{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astartes import train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Chem.SmilesParserParams()\n",
    "params.removeHs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0b7fb",
   "metadata": {},
   "source": [
    "# Read in the data\n",
    "- This csv file was directly taken from [Zenodo](https://zenodo.org/record/6618262#.Y-ZRzMHMLUI) which stores data from the following publication: Kevin A. Spiekermann, Lagnajit Pattanaik, and William H. Green. \"High Accuracy Barrier Heights, Enthalpies, and Rate Coefficients for Chemical Reactions\". In: Sci. Data 9.1 (2022), pp. 1â€“12. [link](https://www.nature.com/articles/s41597-022-01529-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1614e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'ccsdtf12_dz.csv'\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8ee6c",
   "metadata": {},
   "source": [
    "# Random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SPLITS = []\n",
    "sampler = \"random\"\n",
    "for seed in range(5):\n",
    "    # create 85:5:10 data split\n",
    "    _, _, _, train_indices, val_indices, test_indices = train_val_test_split(\n",
    "        np.arange(len(df)),\n",
    "        train_size=0.85,\n",
    "        val_size=0.05,\n",
    "        test_size=0.1,\n",
    "        sampler=sampler,\n",
    "        random_state=seed,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    RANDOM_SPLITS.append([train_indices, val_indices, test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RDB7_splits/RDB7_splits_random.pkl', 'wb') as f:\n",
    "    pkl.dump(RANDOM_SPLITS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a394931",
   "metadata": {},
   "source": [
    "# Scaffold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908df184",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCAFFOLD_SPLITS = []\n",
    "sampler = \"scaffold\"\n",
    "for seed in range(5):\n",
    "    # create 85:5:10 data split\n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_labels,\n",
    "        train_indices,\n",
    "        val_indices,\n",
    "        test_indices,\n",
    "    ) = train_val_test_split(\n",
    "        df.rsmi.values,\n",
    "        train_size=0.85,\n",
    "        val_size=0.05,\n",
    "        test_size=0.1,\n",
    "        sampler=sampler,\n",
    "        random_state=seed,\n",
    "        return_indices=True,\n",
    "    )\n",
    "    SCAFFOLD_SPLITS.append([train_indices, val_indices, test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3208620",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RDB7_splits/RDB7_splits_scaffold.pkl', 'wb') as f:\n",
    "    pkl.dump(SCAFFOLD_SPLITS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269f769",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd40da",
   "metadata": {},
   "source": [
    "Featurize the data using morgan fingerprint with standard settings.\n",
    "\n",
    "Function taken from Chemprop: https://github.com/chemprop/chemprop/blob/master/chemprop/features/features_generators.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MORGAN_RADIUS = 2\n",
    "MORGAN_NUM_BITS = 2048\n",
    "\n",
    "def morgan_counts_features_generator(\n",
    "    mol,\n",
    "    radius=MORGAN_RADIUS,\n",
    "    num_bits=MORGAN_NUM_BITS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a counts-based Morgan fingerprint for a molecule.\n",
    "    :param mol: A molecule (i.e., either a SMILES or an RDKit molecule).\n",
    "    :param radius: Morgan fingerprint radius.\n",
    "    :param num_bits: Number of bits in Morgan fingerprint.\n",
    "    :return: A 1D numpy array containing the counts-based Morgan fingerprint.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    features_vec = AllChem.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n",
    "    features = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(features_vec, features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "morgan_fps = np.zeros((len(df), MORGAN_NUM_BITS))\n",
    "for i, row in df.iterrows():\n",
    "    rmol = Chem.MolFromSmiles(row.rsmi, params)\n",
    "    morgan = morgan_counts_features_generator(rmol)\n",
    "    morgan_fps[i, :] = morgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48589160",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KMEANS_SPLITS = []\n",
    "sampler = \"kmeans\"\n",
    "seed = 0\n",
    "K = 20\n",
    "n_init = 10\n",
    "\n",
    "# cluster the data\n",
    "_, _, _, train_labels, val_labels, test_labels, train_indices, val_indices, test_indices = train_val_test_split(\n",
    "    morgan_fps,\n",
    "    train_size=0.85,\n",
    "    val_size=0.05,\n",
    "    test_size=0.1,\n",
    "    sampler=sampler,\n",
    "    hopts={\"n_clusters\": K, \"n_init\": n_init},\n",
    "    random_state=seed,\n",
    "    return_indices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((train_labels, val_labels, test_labels))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.concatenate((train_indices, val_indices, test_indices))\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985301d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters2indices = {i: [] for i in range(K)}\n",
    "# clusters2rsmiles = {i: [] for i in range(K)}\n",
    "for idx, label in zip(indices, labels):\n",
    "    # rsmi = df.rsmi.values[idx]\n",
    "    # clusters2rsmiles[label].append(rsmi)\n",
    "    clusters2indices[label].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters2sizes = {k: len(v)/len(df) for k, v in clusters2indices.items()}\n",
    "sorted_clusters2sizes = {k: v for k, v in sorted(clusters2sizes.items(), key=lambda item: item[1])}\n",
    "for key, value in sorted_clusters2sizes.items():\n",
    "    print(f'cluster {key} has {value * 100:0.1f} % of the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7411e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the val and test clusters to aim for 85:5:10 splits\n",
    "val_test_cluster_indices = [\n",
    "    ([17],  [15, 16]),\n",
    "    ([13],  [3,  10]),\n",
    "    ([0],   [18, 19]),\n",
    "    ([8],   [12,  9]),\n",
    "    ([14],  [5,   8]),\n",
    "]\n",
    "\n",
    "KMEANS_SPLITS = []\n",
    "for val_keys, test_keys in val_test_cluster_indices:\n",
    "    indices_set = set(clusters2sizes.keys())\n",
    "    print('*'*88)\n",
    "    \n",
    "    # get val indices\n",
    "    val_indices = []\n",
    "    val_clusters = set()\n",
    "    for val_key in val_keys:\n",
    "        val_clusters.add(val_key)\n",
    "        \n",
    "        val_indices_tmp = clusters2indices[val_key]\n",
    "        val_indices.extend(val_indices_tmp)\n",
    "        print(f'Validation group is {val_key} with {len(val_indices_tmp)} samples i.e. {len(val_indices_tmp)/len(df)*100:.1f}%')\n",
    "        indices_set.remove(val_key)\n",
    "    if len(val_keys) > 1:\n",
    "        print(f'Validation group is {val_clusters} with {len(val_indices)} samples i.e. {len(val_indices)/len(df)*100:.1f}%')\n",
    "    print()\n",
    "    \n",
    "    # get test indices\n",
    "    test_indices = []\n",
    "    test_clusters = set()\n",
    "    for test_key in test_keys:\n",
    "        test_clusters.add(test_key)\n",
    "        \n",
    "        test_indices_tmp = clusters2indices[test_key]\n",
    "        test_indices.extend(test_indices_tmp)\n",
    "        print(f'Testing group is {test_key} with {len(test_indices_tmp)} samples i.e. {len(test_indices_tmp)/len(df)*100:.1f}%')\n",
    "        # test_indices = clusters2indices[test_cluster]\n",
    "        indices_set.remove(test_key)\n",
    "    if len(test_keys) > 1:\n",
    "        print(f'Testing group is {test_clusters} with {len(test_indices)} samples i.e. {len(test_indices)/len(df)*100:.1f}%')\n",
    "    print()\n",
    "    \n",
    "    # training indices is the remaining clusters\n",
    "    train_indices = []\n",
    "    for i in indices_set:\n",
    "        train_indices.extend(clusters2indices[i])\n",
    "    print(f'Training groups are {indices_set} with {len(train_indices)} i.e. {len(train_indices)/len(df)*100:.1f}% samples')\n",
    "    \n",
    "    # make sure this adds up to the total\n",
    "    assert (len(train_indices) + len(val_indices) + len(test_indices)) == len(df)\n",
    "    KMEANS_SPLITS.append([train_indices, val_indices, test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RDB7_splits/RDB7_splits_kmeans.pkl', 'wb') as f:\n",
    "    pkl.dump(KMEANS_SPLITS, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
